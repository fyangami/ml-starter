{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens) -> None:\n",
    "        if isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        import collections\n",
    "        counter = collections.Counter(tokens)\n",
    "        tokens = [\n",
    "            k for k, _ in sorted(\n",
    "                counter.items(), key=lambda item: item[1], reverse=True)\n",
    "        ]\n",
    "        tokens.insert(0, '<unk>')\n",
    "        self.tokens_indicates = {\n",
    "            token: idx\n",
    "            for idx, token in enumerate(tokens)\n",
    "        }\n",
    "        self.indicates_tokens = {\n",
    "            v: k\n",
    "            for k, v in self.tokens_indicates.items()\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens_indicates)\n",
    "\n",
    "    def __getitem__(self, keys):\n",
    "        if isinstance(keys, str):\n",
    "            return self.tokens_indicates[keys]\n",
    "        if isinstance(keys, list):\n",
    "            return [self.__getitem__(key) for key in keys]\n",
    "        if isinstance(keys, (torch.Tensor)):\n",
    "            keys = keys.reshape(-1)\n",
    "            return ''.join(self.indicates_tokens[int(keys[i])]\n",
    "                           for i in range(keys.numel()))\n",
    "        return self.indicates_tokens[keys]\n",
    "\n",
    "\n",
    "def tokenize(lines: list, steps=32):\n",
    "    import jieba\n",
    "    import zhconv\n",
    "    import re\n",
    "    truncate = lambda sen, l: sen[:l] if len(sen) > l else sen + ['<pad>'] * (\n",
    "        l - len(sen))\n",
    "    en, zh = [], []\n",
    "    for line in lines:\n",
    "        sentence_en, sentence_zh, _ = line.split('\\t')\n",
    "        sentence_en = [\n",
    "            i for i in re.sub('[^A-Za-z ]+', lambda m: f' {m.group()} ',\n",
    "                              sentence_en).lower().split(' ')\n",
    "            if i != '' and i != ' '\n",
    "        ]\n",
    "        sentence_zh = list(\n",
    "            jieba.cut(zhconv.convert(sentence_zh, 'zh-cn'), cut_all=False))\n",
    "        sentence_en = sentence_en + ['<eos>']\n",
    "        sentence_zh = ['<bos>'] + sentence_zh + ['<eos>']\n",
    "        sentence_en = truncate(sentence_en, steps)\n",
    "        sentence_zh = truncate(sentence_zh, steps)\n",
    "        en.append(sentence_en)\n",
    "        zh.append(sentence_zh)\n",
    "    return en, zh\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    with open('../rnn/en_zh.trans.txt', 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "\n",
    "class _Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_raw, steps=24) -> None:\n",
    "        super().__init__()\n",
    "        en, zh = data_raw\n",
    "        self.vocab_en, self.vocab_zh = Vocab(en), Vocab(zh)\n",
    "        self.corpus_en, self.corpus_zh = torch.tensor(\n",
    "            self.vocab_en[en],\n",
    "            dtype=torch.float32), torch.tensor(self.vocab_zh[zh],\n",
    "                                               dtype=torch.float32)\n",
    "        self.valid_len_en, self.valid_len_zh = (\n",
    "            self.corpus_en != self.vocab_en['<pad>']).sum(\n",
    "                dim=1), (self.corpus_zh != self.vocab_zh['<pad>']).sum(dim=1)\n",
    "        self._len = len(self.corpus_en)\n",
    "        del en, zh\n",
    "        assert self._len == len(self.corpus_zh) == len(\n",
    "            self.valid_len_en) == len(self.valid_len_zh)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.corpus_en[idx], self.valid_len_en[idx], self.corpus_zh[\n",
    "            idx], self.valid_len_zh[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = _Dataset(tokenize(read_data()), steps=19)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "train_iter = iter(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae33f7c48cc3e1271596d1bf08ce4d5e6d6f7129ff8bbb83bbb95ed8addff62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
