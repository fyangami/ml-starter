{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens) -> None:\n",
    "        if isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        import collections\n",
    "        counter = collections.Counter(tokens)\n",
    "        tokens = [\n",
    "            k for k, _ in sorted(\n",
    "                counter.items(), key=lambda item: item[1], reverse=True)\n",
    "        ]\n",
    "        tokens.insert(0, '<unk>')\n",
    "        self.tokens_indicates = {\n",
    "            token: idx\n",
    "            for idx, token in enumerate(tokens)\n",
    "        }\n",
    "        self.indicates_tokens = {\n",
    "            v: k\n",
    "            for k, v in self.tokens_indicates.items()\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens_indicates)\n",
    "\n",
    "    def __getitem__(self, keys):\n",
    "        if isinstance(keys, str):\n",
    "            return self.tokens_indicates[keys]\n",
    "        if isinstance(keys, list):\n",
    "            return [self.__getitem__(key) for key in keys]\n",
    "        if isinstance(keys, (torch.Tensor)):\n",
    "            keys = keys.reshape(-1)\n",
    "            return ''.join(self.indicates_tokens[int(keys[i])]\n",
    "                           for i in range(keys.numel()))\n",
    "        return self.indicates_tokens[keys]\n",
    "\n",
    "\n",
    "def tokenize(lines: list, steps=32):\n",
    "    import jieba\n",
    "    import zhconv\n",
    "    import re\n",
    "    truncate = lambda sen, l: sen[:l] if len(sen) > l else sen + ['<pad>'] * (\n",
    "        l - len(sen))\n",
    "    en, zh = [], []\n",
    "    for line in lines:\n",
    "        sentence_en, sentence_zh, _ = line.split('\\t')\n",
    "        sentence_en = [\n",
    "            i for i in re.sub('[^A-Za-z ]+', lambda m: f' {m.group()} ',\n",
    "                              sentence_en).lower().split(' ')\n",
    "            if i != '' and i != ' '\n",
    "        ]\n",
    "        sentence_zh = list(\n",
    "            jieba.cut(zhconv.convert(sentence_zh, 'zh-cn'), cut_all=False))\n",
    "        sentence_en = sentence_en + ['<eos>']\n",
    "        sentence_zh = ['<bos>'] + sentence_zh + ['<eos>']\n",
    "        sentence_en = truncate(sentence_en, steps)\n",
    "        sentence_zh = truncate(sentence_zh, steps)\n",
    "        en.append(sentence_en)\n",
    "        zh.append(sentence_zh)\n",
    "    return en, zh\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    with open('../rnn/en_zh.trans.txt', 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "\n",
    "class _Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_raw) -> None:\n",
    "        super().__init__()\n",
    "        en, zh = data_raw\n",
    "        self.vocab_en, self.vocab_zh = Vocab(en), Vocab(zh)\n",
    "        self.corpus_en, self.corpus_zh = torch.tensor(\n",
    "            self.vocab_en[en],\n",
    "            dtype=torch.int64), torch.tensor(self.vocab_zh[zh],\n",
    "                                               dtype=torch.int64)\n",
    "        self.valid_len_en, self.valid_len_zh = (\n",
    "            self.corpus_en != self.vocab_en['<pad>']).sum(\n",
    "                dim=1), (self.corpus_zh != self.vocab_zh['<pad>']).sum(dim=1)\n",
    "        self._len = len(self.corpus_en)\n",
    "        del en, zh\n",
    "        assert self._len == len(self.corpus_zh) == len(\n",
    "            self.valid_len_en) == len(self.valid_len_zh)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.corpus_en[idx], self.valid_len_en[idx], self.corpus_zh[\n",
    "            idx], self.valid_len_zh[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 n_hiddens,\n",
    "                 n_layers,\n",
    "                 dropout=0.) -> None:\n",
    "        super().__init__()\n",
    "        # embedding layer similar as `one-hot` transformation.\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, n_hiddens, n_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = (batch_size, n_steps)\n",
    "        # embed.shape = (n_steps, batch_size, embed_size)\n",
    "        embed = self.embedding(x.T.type(torch.int64))\n",
    "        # output.shape = (n_steps, batch_size, n_hiddens)\n",
    "        # state.shape = (n_layers, batch_size, n_hiddens)\n",
    "        output, state = self.rnn(embed)\n",
    "        return output, state\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 n_hiddens,\n",
    "                 n_layers,\n",
    "                 dropout=0.) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + n_hiddens,\n",
    "                          n_hiddens,\n",
    "                          n_layers,\n",
    "                          dropout=dropout)\n",
    "        self.fc = nn.Linear(n_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, encode_outputs):\n",
    "        encode_output, encode_state = encode_outputs\n",
    "        return encode_state\n",
    "\n",
    "    def forward(self, x, es: torch.Tensor):\n",
    "        embed = self.embedding(x.T.type(torch.int64))\n",
    "        # context using last layer of encode state\n",
    "        # c.shape = (batch_size, n_hiddens)\n",
    "        c = es[-1]\n",
    "        c = c.repeat(embed.shape[0], 1, 1)\n",
    "        embed_c = torch.cat((embed, c), -1)\n",
    "        # decoder initial state as final `output_state` of encoder\n",
    "        output, state = self.rnn(embed_c, es)\n",
    "        output = self.fc(output)\n",
    "        output = output.permute((1, 2, 0))\n",
    "        # output.shape = (batch_size, n_steps, vocab_size)\n",
    "        return output, state\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size_source,\n",
    "                 vocab_size_target,\n",
    "                 embed_size,\n",
    "                 n_hiddens,\n",
    "                 n_layers,\n",
    "                 dropout=0.) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size=vocab_size_source,\n",
    "                               embed_size=embed_size,\n",
    "                               n_hiddens=n_hiddens,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=dropout)\n",
    "        self.decoder = Decoder(vocab_size=vocab_size_target,\n",
    "                               embed_size=embed_size,\n",
    "                               n_hiddens=n_hiddens,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        output = self.encoder(x)\n",
    "        decode_state = self.decoder.init_state(output)\n",
    "        output, _ = self.decoder(y, decode_state)\n",
    "        return output\n",
    "\n",
    "def loss_masking(loss, y, pad_indicate):\n",
    "    mask = (y != pad_indicate).type(torch.float32)\n",
    "    return (loss * mask).sum() / mask.sum()\n",
    "\n",
    "def grad_clip(net: nn.Module, clip_val=1):\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > clip_val:\n",
    "        for parm in params:\n",
    "            parm.grad[:] *= clip_val / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "STEPS = 19\n",
    "EMBED_SIZE = 256\n",
    "HIDDENS = 256\n",
    "LAYERS = 3\n",
    "DROPOUT = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [15/50"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/fyang/code/ml/ml-starter/nlp/trans.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fyang/code/ml/ml-starter/nlp/trans.ipynb#ch0000002?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_masking(loss, y, dataset\u001b[39m.\u001b[39mvocab_zh[\u001b[39m'\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fyang/code/ml/ml-starter/nlp/trans.ipynb#ch0000002?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fyang/code/ml/ml-starter/nlp/trans.ipynb#ch0000002?line=23'>24</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fyang/code/ml/ml-starter/nlp/trans.ipynb#ch0000002?line=24'>25</a>\u001b[0m     grad_clip(net)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fyang/code/ml/ml-starter/nlp/trans.ipynb#ch0000002?line=25'>26</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.conda/envs/mlenv/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/mlenv/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = _Dataset(tokenize(read_data(), steps=STEPS))\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True)\n",
    "net = EncoderDecoder(vocab_size_source=len(dataset.vocab_en),\n",
    "                     vocab_size_target=len(dataset.vocab_zh),\n",
    "                     embed_size=EMBED_SIZE,\n",
    "                     n_hiddens=HIDDENS,\n",
    "                     n_layers=LAYERS,\n",
    "                     dropout=DROPOUT)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "losses, loss = [], None\n",
    "net.zero_grad()\n",
    "for epoch in range(0, EPOCHS + 1):\n",
    "    train_iter = iter(dataloader)\n",
    "    for x, _, y, _ in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        # 1024 32 28\n",
    "        output = net(x, y)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss = loss_masking(loss, y, dataset.vocab_zh['<pad>'])\n",
    "        with torch.no_grad():\n",
    "            loss.backward()\n",
    "            grad_clip(net)\n",
    "            optimizer.step()\n",
    "    print(f\"\\repoch: [{epoch}/{EPOCHS}\", end='')\n",
    "    losses.append(loss.detach().numpy())\n",
    "    # print(f'loss: {loss: .6f}')\n",
    "print()\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae33f7c48cc3e1271596d1bf08ce4d5e6d6f7129ff8bbb83bbb95ed8addff62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
