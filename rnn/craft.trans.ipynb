{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import zhconv\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        counter = Vocab.count_corpus(tokens)\n",
    "        # 对词频率排序\n",
    "        self.__token_freqs = sorted(counter.items(),\n",
    "                                    key=lambda x: x[1],\n",
    "                                    reverse=True)\n",
    "        self.index_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_index = {\n",
    "            token: idx\n",
    "            for idx, token in enumerate(self.index_to_token)\n",
    "        }\n",
    "        for token, freq in self.__token_freqs:\n",
    "            if freq >= min_freq and token not in self.token_to_index:\n",
    "                self.index_to_token.append(token)\n",
    "                self.token_to_index[token] = len(self.index_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_to_token)\n",
    "\n",
    "    def get_tokens(self, indicates):\n",
    "        if not isinstance(indicates, (list, tuple)):\n",
    "            return self.index_to_token[indicates]\n",
    "        return ''.join([self.get_tokens(index) for index in indicates])\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_index.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self.__token_freqs\n",
    "\n",
    "    @staticmethod\n",
    "    def count_corpus(tokens):\n",
    "        if isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        from collections import Counter\n",
    "        return Counter(tokens)\n",
    "\n",
    "\n",
    "def truncate_and_pad(line, steps, padding_token):\n",
    "    \"\"\"\n",
    "    \\{填充||截断\\}序列，使序列长度保持一致\n",
    "    \"\"\"\n",
    "    if len(line) > steps:\n",
    "        return line[:steps]\n",
    "    return line + [padding_token] * (steps - len(line))\n",
    "\n",
    "\n",
    "def load_datasets(steps=20, batch_size=50):\n",
    "    \"\"\"\n",
    "    预处理数据并封装成tf.data.Dataset\n",
    "    \"\"\"\n",
    "    with open('./en_zh.trans.txt', 'r') as data_file:\n",
    "        lines = data_file.readlines()\n",
    "    # print(zhconv.convert(s[1], 'zh-cn'))\n",
    "    en, zh = [], []\n",
    "    for line in lines:\n",
    "        split = line.split('\\t')\n",
    "        en.append(\n",
    "            truncate_and_pad(\n",
    "                re.sub('[^A-Za-z]+', ' ', split[0]).strip().lower().split(' ')\n",
    "                + ['<eos>'], steps, '<pad>')), zh.append(\n",
    "                    truncate_and_pad(\n",
    "                        list(\n",
    "                            jieba.cut(zhconv.convert(split[1], 'zh-cn'),\n",
    "                                      cut_all=False)) + ['<eos>'], steps,\n",
    "                    '<pad>'))\n",
    "    en_vocab, zh_vocab = Vocab(\n",
    "        en, min_freq=2,\n",
    "        reserved_tokens=['<pad>', '<bos>', '<eos>'\n",
    "                         ]), Vocab(zh,\n",
    "                                   min_freq=2,\n",
    "                                   reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    en = tf.constant([en_vocab[line] for line in en], dtype='float32')\n",
    "    zh = tf.constant([zh_vocab[line] for line in zh], dtype='int32')\n",
    "    en_len = tf.reduce_sum(tf.cast(en != en_vocab['<pad>'], dtype='int32'), axis=1)\n",
    "    zh_len = tf.reduce_sum(tf.cast(zh != zh_vocab['<pad>'], dtype='int32'), axis=1)\n",
    "    ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(en),\n",
    "        tf.data.Dataset.from_tensor_slices(en_len),\n",
    "        tf.data.Dataset.from_tensor_slices(zh),\n",
    "        tf.data.Dataset.from_tensor_slices(zh_len),\n",
    "    )\n",
    "    # en.shape=(batch_size, steps)\n",
    "    train_iter = tf.data.Dataset.zip(ds).shuffle(buffer_size=len(en)).batch(batch_size=batch_size)\n",
    "    return train_iter, en_vocab, zh_vocab\n",
    "\n",
    "BATCH_SIZE, STEPS = 512, 15\n",
    "train_iter, en_vocab, zh_vocab = load_datasets(batch_size=BATCH_SIZE, steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hiddens, layers, dropout=0., **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "        self.rnn_net = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells([\n",
    "                tf.keras.layers.GRUCell(hiddens, dropout=dropout) for _ in range(layers)\n",
    "            ]), return_sequences=True, return_state=True)\n",
    "    \n",
    "    def call(self, x, *args, **kwargs):\n",
    "        x = self.embedding(x)\n",
    "        y = self.rnn_net(x, *args, **kwargs)\n",
    "        state = y[1:]\n",
    "        return y[0], state\n",
    "\n",
    "class Seq2SeqDecoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hiddens, layers, dropout=0., **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "        self.rnn_net = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells([\n",
    "            tf.keras.layers.GRUCell(hiddens, dropout=dropout) for _ in range(layers)\n",
    "            ]), return_sequences=True, return_state=True)\n",
    "        self.output_layer = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def init_state(self, encode, *args):\n",
    "        return encode[1]\n",
    "        \n",
    "    def call(self, x, state, **kwargs):\n",
    "        x = self.embedding(x)\n",
    "        context = tf.repeat(tf.expand_dims(state[-1], axis=1), repeats=x.shape[1], axis=1)\n",
    "        x_ctx = tf.concat((x, context), axis=2)\n",
    "        y = self.rnn_net(x, state, **kwargs)\n",
    "        state = y[1:]\n",
    "        y = self.output_layer(y[0])\n",
    "        return y, state\n",
    "\n",
    "class EncoderDecoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def call(self, encode_x, decode_x, *args, **kwargs):\n",
    "        encode = self.encoder(encode_x, *args, **kwargs)\n",
    "        state = self.decoder.init_state(encode, *args)\n",
    "        return self.decoder(decode_x, state, **kwargs)\n",
    "    \n",
    "    def fit(self, train_iter, target_vocab, epochs=10, lr=1e-3):\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, xl, y, yl) in enumerate(train_iter):\n",
    "                bos = tf.reshape(tf.constant([target_vocab['<bos>']] * y.shape[0]), shape=(-1, 1))\n",
    "                decode_x = tf.concat([bos, tf.cast(y[:, :-1], dtype='int32')] , 1)  # 给y加入<bos> 忽略末尾的<eos>\n",
    "                with tf.GradientTape() as gt:\n",
    "                    y_hat, _ = self.call(x, decode_x, training=True)\n",
    "                    loss = MaskedSoftmaxLoss(yl)(y, y_hat)\n",
    "                grads = gt.gradient(loss, self.trainable_variables)\n",
    "                grads = self.gradient_clip(grads, 1)\n",
    "                optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "            print(f'epoch[{epoch + 1}\\\\{epochs} loss: {tf.reduce_mean(loss)}')\n",
    "    \n",
    "    def gradient_clip(self, grads, theta):\n",
    "        \"\"\"\n",
    "            梯度裁剪，防止梯度爆炸问题\n",
    "        \"\"\"\n",
    "        theta = tf.constant(theta, dtype=\"float32\")\n",
    "        new_grads = []\n",
    "        for grad in grads:\n",
    "            new_grads.append(\n",
    "                tf.convert_to_tensor(grad) if isinstance(\n",
    "                    grad, tf.IndexedSlices) else grad)\n",
    "        # L2范数\n",
    "        norm = tf.math.sqrt(\n",
    "            sum((tf.reduce_sum(grad**2).numpy() for grad in new_grads)))\n",
    "        norm = tf.cast(norm, \"float32\")\n",
    "        if tf.greater(norm, theta):\n",
    "            for i, grad in enumerate(new_grads):\n",
    "                new_grads[i] = grad * theta / norm\n",
    "        return new_grads\n",
    "    \n",
    "    def predict(self, src, src_vocab, target_vocab, steps):\n",
    "        src_tokens = src_vocab[src.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "        src_valid_len = tf.constant([len(src_tokens)])\n",
    "        src_tokens = tf.constant(truncate_and_pad(src_tokens, steps, src_vocab['<pad>']), dtype='float32')\n",
    "        encode_x = tf.expand_dims(src_tokens, axis=0)\n",
    "        encode_outputs = self.encoder(encode_x, training=False)\n",
    "        state = self.decoder.init_state(encode_outputs, src_valid_len)\n",
    "        predict = []\n",
    "        decode_x = tf.expand_dims(tf.constant([target_vocab['<bos>']]), axis=0)\n",
    "        for _ in range(steps):\n",
    "            y, state = net.decoder(decode_x, state, training=False)\n",
    "            decode_x = tf.argmax(y, axis=2)\n",
    "            pred = tf.squeeze(decode_x, axis=0)\n",
    "            if pred == target_vocab['<eos>']:\n",
    "                break;\n",
    "            predict.append(pred.numpy())\n",
    "        return ''.join([target_vocab.get_tokens(word[0]) for word in predict])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxLoss(tf.keras.losses.Loss):\n",
    "    \n",
    "    def __init__(self, valid_len):\n",
    "        super().__init__(reduction='none')\n",
    "        self.valid_len = valid_len\n",
    "        self._loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    \n",
    "    def call(self, y, y_hat):\n",
    "        mask = tf.ones_like(y, dtype='float32')\n",
    "        mask = self.sequence_mask(mask)\n",
    "        y = tf.one_hot(y, depth=y_hat.shape[-1])\n",
    "        _loss = self._loss_fn(y, y_hat)\n",
    "        return tf.reduce_mean(mask * _loss, axis=1)\n",
    "\n",
    "    def sequence_mask(self, x, value=0):\n",
    "        \"\"\"\n",
    "        由于做了固定长度的填充，在预测时要忽略掉\n",
    "        \"\"\"\n",
    "        # x.shape=(batch_size, steps)\n",
    "        # xl.shape=(steps, )\n",
    "        # (1, 32) (32, 1)\n",
    "        mask = tf.range(start=0, limit=x.shape[1],\n",
    "                        dtype='float32')[None, :] < tf.cast(self.valid_len[:, None],\n",
    "                                                            dtype='float32')\n",
    "        if len(x.shape) == 3:\n",
    "            return tf.where(tf.expand_dims(mask, axis=-1), x, value)\n",
    "        else:\n",
    "            return  tf.where(mask, x, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1\\200 loss: 2.863422393798828\n",
      "epoch[2\\200 loss: 2.680830478668213\n",
      "epoch[3\\200 loss: 2.4347567558288574\n",
      "epoch[4\\200 loss: 2.3846709728240967\n",
      "epoch[5\\200 loss: 2.392573118209839\n",
      "epoch[6\\200 loss: 2.303725242614746\n",
      "epoch[7\\200 loss: 2.3967225551605225\n",
      "epoch[8\\200 loss: 2.2686619758605957\n",
      "epoch[9\\200 loss: 2.1332828998565674\n",
      "epoch[10\\200 loss: 2.171907901763916\n",
      "epoch[11\\200 loss: 2.1042423248291016\n",
      "epoch[12\\200 loss: 2.1073410511016846\n",
      "epoch[13\\200 loss: 2.0729575157165527\n",
      "epoch[14\\200 loss: 1.9905121326446533\n",
      "epoch[15\\200 loss: 1.9423660039901733\n",
      "epoch[16\\200 loss: 1.8784390687942505\n",
      "epoch[17\\200 loss: 1.9707272052764893\n",
      "epoch[18\\200 loss: 1.9936015605926514\n",
      "epoch[19\\200 loss: 1.8809469938278198\n",
      "epoch[20\\200 loss: 1.9264605045318604\n",
      "epoch[21\\200 loss: 1.9051804542541504\n",
      "epoch[22\\200 loss: 1.8375962972640991\n",
      "epoch[23\\200 loss: 1.849548101425171\n",
      "epoch[24\\200 loss: 1.8886387348175049\n",
      "epoch[25\\200 loss: 1.9044933319091797\n",
      "epoch[26\\200 loss: 1.8290139436721802\n",
      "epoch[27\\200 loss: 1.8134591579437256\n",
      "epoch[28\\200 loss: 1.811802625656128\n",
      "epoch[29\\200 loss: 1.754947304725647\n",
      "epoch[30\\200 loss: 1.778112769126892\n",
      "epoch[31\\200 loss: 1.7351126670837402\n",
      "epoch[32\\200 loss: 1.7243558168411255\n",
      "epoch[33\\200 loss: 1.6984065771102905\n",
      "epoch[34\\200 loss: 1.6358988285064697\n",
      "epoch[35\\200 loss: 1.6243271827697754\n",
      "epoch[36\\200 loss: 1.6129165887832642\n",
      "epoch[37\\200 loss: 1.7305206060409546\n",
      "epoch[38\\200 loss: 1.6472399234771729\n",
      "epoch[39\\200 loss: 1.6401280164718628\n",
      "epoch[40\\200 loss: 1.6677764654159546\n",
      "epoch[41\\200 loss: 1.6095023155212402\n",
      "epoch[42\\200 loss: 1.6525949239730835\n",
      "epoch[43\\200 loss: 1.6742743253707886\n",
      "epoch[44\\200 loss: 1.6773840188980103\n",
      "epoch[45\\200 loss: 1.5622919797897339\n",
      "epoch[46\\200 loss: 1.6046741008758545\n",
      "epoch[47\\200 loss: 1.602428913116455\n",
      "epoch[48\\200 loss: 1.5316990613937378\n",
      "epoch[49\\200 loss: 1.5394585132598877\n",
      "epoch[50\\200 loss: 1.5403202772140503\n",
      "epoch[51\\200 loss: 1.574713945388794\n",
      "epoch[52\\200 loss: 1.5358045101165771\n",
      "epoch[53\\200 loss: 1.5922231674194336\n",
      "epoch[54\\200 loss: 1.4846460819244385\n",
      "epoch[55\\200 loss: 1.5160839557647705\n",
      "epoch[56\\200 loss: 1.4561508893966675\n",
      "epoch[57\\200 loss: 1.5670512914657593\n",
      "epoch[58\\200 loss: 1.4829665422439575\n",
      "epoch[59\\200 loss: 1.4896851778030396\n",
      "epoch[60\\200 loss: 1.4636038541793823\n",
      "epoch[61\\200 loss: 1.551451563835144\n",
      "epoch[62\\200 loss: 1.4956505298614502\n",
      "epoch[63\\200 loss: 1.4645673036575317\n",
      "epoch[64\\200 loss: 1.433963418006897\n",
      "epoch[65\\200 loss: 1.4235039949417114\n",
      "epoch[66\\200 loss: 1.4172405004501343\n",
      "epoch[67\\200 loss: 1.3393173217773438\n",
      "epoch[68\\200 loss: 1.4344426393508911\n",
      "epoch[69\\200 loss: 1.4337360858917236\n",
      "epoch[70\\200 loss: 1.3585330247879028\n",
      "epoch[71\\200 loss: 1.4627879858016968\n",
      "epoch[72\\200 loss: 1.3394659757614136\n",
      "epoch[73\\200 loss: 1.4639785289764404\n",
      "epoch[74\\200 loss: 1.4132822751998901\n",
      "epoch[75\\200 loss: 1.427412509918213\n",
      "epoch[76\\200 loss: 1.4065210819244385\n",
      "epoch[77\\200 loss: 1.337357759475708\n",
      "epoch[78\\200 loss: 1.456049919128418\n",
      "epoch[79\\200 loss: 1.3420295715332031\n",
      "epoch[80\\200 loss: 1.2731010913848877\n",
      "epoch[81\\200 loss: 1.4010099172592163\n",
      "epoch[82\\200 loss: 1.339693307876587\n",
      "epoch[83\\200 loss: 1.2970962524414062\n",
      "epoch[84\\200 loss: 1.3543111085891724\n",
      "epoch[85\\200 loss: 1.382017970085144\n",
      "epoch[86\\200 loss: 1.3075627088546753\n",
      "epoch[87\\200 loss: 1.317773699760437\n",
      "epoch[88\\200 loss: 1.3059364557266235\n",
      "epoch[89\\200 loss: 1.2390358448028564\n",
      "epoch[90\\200 loss: 1.24527907371521\n",
      "epoch[91\\200 loss: 1.283878207206726\n",
      "epoch[92\\200 loss: 1.2611244916915894\n",
      "epoch[93\\200 loss: 1.2511098384857178\n",
      "epoch[94\\200 loss: 1.189598798751831\n",
      "epoch[95\\200 loss: 1.233865737915039\n",
      "epoch[96\\200 loss: 1.235313057899475\n",
      "epoch[97\\200 loss: 1.3494431972503662\n",
      "epoch[98\\200 loss: 1.2538524866104126\n",
      "epoch[99\\200 loss: 1.233353614807129\n",
      "epoch[100\\200 loss: 1.2586612701416016\n",
      "epoch[101\\200 loss: 1.28792142868042\n",
      "epoch[102\\200 loss: 1.3072664737701416\n",
      "epoch[103\\200 loss: 1.2652413845062256\n",
      "epoch[104\\200 loss: 1.2456345558166504\n",
      "epoch[105\\200 loss: 1.2249500751495361\n",
      "epoch[106\\200 loss: 1.235211968421936\n",
      "epoch[107\\200 loss: 1.2766990661621094\n",
      "epoch[108\\200 loss: 1.2309868335723877\n",
      "epoch[109\\200 loss: 1.2178767919540405\n",
      "epoch[110\\200 loss: 1.1857421398162842\n",
      "epoch[111\\200 loss: 1.1813093423843384\n",
      "epoch[112\\200 loss: 1.1446009874343872\n",
      "epoch[113\\200 loss: 1.196399450302124\n",
      "epoch[114\\200 loss: 1.1716740131378174\n",
      "epoch[115\\200 loss: 1.2114958763122559\n",
      "epoch[116\\200 loss: 1.160571575164795\n",
      "epoch[117\\200 loss: 1.2038204669952393\n",
      "epoch[118\\200 loss: 1.2173247337341309\n",
      "epoch[119\\200 loss: 1.095816731452942\n",
      "epoch[120\\200 loss: 1.1296521425247192\n",
      "epoch[121\\200 loss: 1.189929485321045\n",
      "epoch[122\\200 loss: 1.1136767864227295\n",
      "epoch[123\\200 loss: 1.152085304260254\n",
      "epoch[124\\200 loss: 1.116493821144104\n",
      "epoch[125\\200 loss: 1.1852892637252808\n",
      "epoch[126\\200 loss: 1.1995891332626343\n",
      "epoch[127\\200 loss: 1.0989022254943848\n",
      "epoch[128\\200 loss: 1.1717336177825928\n",
      "epoch[129\\200 loss: 1.106570839881897\n",
      "epoch[130\\200 loss: 1.1529624462127686\n",
      "epoch[131\\200 loss: 1.0707629919052124\n",
      "epoch[132\\200 loss: 1.141933798789978\n",
      "epoch[133\\200 loss: 1.077822208404541\n",
      "epoch[134\\200 loss: 1.0838813781738281\n",
      "epoch[135\\200 loss: 1.0914084911346436\n",
      "epoch[136\\200 loss: 1.045365333557129\n",
      "epoch[137\\200 loss: 1.1572147607803345\n",
      "epoch[138\\200 loss: 1.0459409952163696\n",
      "epoch[139\\200 loss: 1.1076105833053589\n",
      "epoch[140\\200 loss: 1.0542901754379272\n",
      "epoch[141\\200 loss: 1.0532110929489136\n",
      "epoch[142\\200 loss: 1.103694200515747\n",
      "epoch[143\\200 loss: 1.0904598236083984\n",
      "epoch[144\\200 loss: 1.0547677278518677\n",
      "epoch[145\\200 loss: 1.0589004755020142\n",
      "epoch[146\\200 loss: 1.0903337001800537\n",
      "epoch[147\\200 loss: 1.010391354560852\n",
      "epoch[148\\200 loss: 1.0945433378219604\n",
      "epoch[149\\200 loss: 1.0189433097839355\n",
      "epoch[150\\200 loss: 1.076688289642334\n",
      "epoch[151\\200 loss: 1.0081743001937866\n",
      "epoch[152\\200 loss: 1.0319290161132812\n",
      "epoch[153\\200 loss: 1.0430588722229004\n",
      "epoch[154\\200 loss: 1.0130311250686646\n",
      "epoch[155\\200 loss: 1.0673829317092896\n",
      "epoch[156\\200 loss: 1.0339882373809814\n",
      "epoch[157\\200 loss: 0.9706099629402161\n",
      "epoch[158\\200 loss: 0.9977158308029175\n",
      "epoch[159\\200 loss: 1.0189837217330933\n",
      "epoch[160\\200 loss: 1.0072776079177856\n",
      "epoch[161\\200 loss: 1.007922649383545\n",
      "epoch[162\\200 loss: 1.058732032775879\n",
      "epoch[163\\200 loss: 0.9967877864837646\n",
      "epoch[164\\200 loss: 0.9920473694801331\n",
      "epoch[165\\200 loss: 0.9830726385116577\n",
      "epoch[166\\200 loss: 1.0200693607330322\n",
      "epoch[167\\200 loss: 1.007905125617981\n",
      "epoch[168\\200 loss: 0.977245569229126\n",
      "epoch[169\\200 loss: 0.9691221714019775\n",
      "epoch[170\\200 loss: 1.01344895362854\n",
      "epoch[171\\200 loss: 0.9492910504341125\n",
      "epoch[172\\200 loss: 0.9341902732849121\n",
      "epoch[173\\200 loss: 0.9906903505325317\n",
      "epoch[174\\200 loss: 1.019398808479309\n",
      "epoch[175\\200 loss: 0.9772263169288635\n",
      "epoch[176\\200 loss: 0.9723227620124817\n",
      "epoch[177\\200 loss: 1.0154236555099487\n",
      "epoch[178\\200 loss: 0.9227412939071655\n",
      "epoch[179\\200 loss: 0.9738418459892273\n",
      "epoch[180\\200 loss: 0.9195210933685303\n",
      "epoch[181\\200 loss: 1.0197570323944092\n",
      "epoch[182\\200 loss: 0.9378089904785156\n",
      "epoch[183\\200 loss: 0.9781386852264404\n",
      "epoch[184\\200 loss: 0.9855728149414062\n",
      "epoch[185\\200 loss: 0.9467718005180359\n",
      "epoch[186\\200 loss: 0.8833705186843872\n",
      "epoch[187\\200 loss: 0.9446484446525574\n",
      "epoch[188\\200 loss: 0.9295762777328491\n",
      "epoch[189\\200 loss: 0.9269636869430542\n",
      "epoch[190\\200 loss: 0.8910199999809265\n",
      "epoch[191\\200 loss: 0.9116348028182983\n",
      "epoch[192\\200 loss: 0.9978488683700562\n",
      "epoch[193\\200 loss: 0.9258395433425903\n",
      "epoch[194\\200 loss: 0.8808838129043579\n",
      "epoch[195\\200 loss: 0.8618798851966858\n",
      "epoch[196\\200 loss: 0.9220371842384338\n",
      "epoch[197\\200 loss: 0.8914076685905457\n",
      "epoch[198\\200 loss: 0.8655068278312683\n",
      "epoch[199\\200 loss: 0.9351577162742615\n",
      "epoch[200\\200 loss: 0.9517381191253662\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE, HIDDENTS, LAYERS, DROPOUT = 64, 64, 2, .1\n",
    "\n",
    "encoder = Seq2SeqEncoder(len(en_vocab), EMBED_SIZE, HIDDENTS, LAYERS, DROPOUT)\n",
    "decoder = Seq2SeqDecoder(len(zh_vocab), EMBED_SIZE, HIDDENTS, LAYERS, DROPOUT)\n",
    "\n",
    "net = EncoderDecoder(encoder=encoder, decoder=decoder)\n",
    "net.fit(train_iter, zh_vocab, epochs=200, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文：Hello，翻译结果：你好。\n",
      "原文：can you help me，翻译结果：你能帮我吗？\n",
      "原文：i need help，翻译结果：我需要帮助。\n",
      "原文：please help me，翻译结果：请帮我。\n",
      "原文：i am a student，翻译结果：我是个学生。\n",
      "原文：i love you，翻译结果：我爱你。\n",
      "原文：i written some code，翻译结果：我写了一封信。\n",
      "原文：we are friends，翻译结果：我们是朋友。\n"
     ]
    }
   ],
   "source": [
    "en = [\n",
    "    \"Hello\",\n",
    "    \"can you help me\",\n",
    "    \"i need help\",\n",
    "    \"please help me\",\n",
    "    \"i am a student\",\n",
    "    \"i love you\",\n",
    "    \"i written some code\",\n",
    "    \"we are friends\"\n",
    "]\n",
    "for source in en:\n",
    "    target = net.predict(source, en_vocab, zh_vocab, steps=STEPS)\n",
    "    print(f\"原文：{source}，翻译结果：{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很好。'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(\"good idea\", en_vocab, zh_vocab, steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好。'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(\"Hi\", en_vocab, zh_vocab, steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我有一个非常喜欢的苹果。'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(\"i have an apple\", en_vocab, zh_vocab, steps=STEPS)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae33f7c48cc3e1271596d1bf08ce4d5e6d6f7129ff8bbb83bbb95ed8addff62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
