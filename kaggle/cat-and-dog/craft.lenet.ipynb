{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 6\n",
    "ETA = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[ 1\\6 speed\\14.70s (==================>  loss: 1.768751 acc: 0.720 valid_acc: 0.720\n",
      "epoch[ 2\\6 speed\\11.98s (==================>  loss: 1.660675 acc: 0.820 valid_acc: 0.840\n",
      "epoch[ 3\\6 speed\\12.08s (==================>  loss: 1.654519 acc: 0.800 valid_acc: 0.800\n",
      "epoch[ 4\\6 speed\\12.08s (==================>  loss: 1.600165 acc: 0.860 valid_acc: 0.840\n",
      "epoch[ 5\\6 speed\\12.04s (==================>  loss: 1.567173 acc: 0.900 valid_acc: 0.980\n",
      "epoch[ 6\\6 speed\\12.03s (==================>  loss: 1.495340 acc: 0.960 valid_acc: 0.940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([7, 2, 1, ..., 4, 5, 6])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.lenet import LeNet\n",
    "\n",
    "from mnist import train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_data = train_images()\n",
    "train_labels = train_labels()\n",
    "\n",
    "train_data = tf.constant(train_data / 255., dtype=tf.dtypes.float32)\n",
    "train_labels = tf.constant(train_labels,dtype=tf.dtypes.int32)\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "train_labels = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "train_iter = tf.data.Dataset.zip((train_data, train_labels))\n",
    "train_iter = train_iter.shuffle(buffer_size=len(train_data), reshuffle_each_iteration=True).batch(batch_size = BATCH_SIZE, drop_remainder=True)\n",
    "net = LeNet(10, input_shape=(28, 28))\n",
    "net.fit(train_iter, epochs=EPOCHS, lr=ETA)\n",
    "\n",
    "test_data = test_images()\n",
    "test_labels = test_labels()\n",
    "test_data = tf.constant(test_data / 255., dtype=tf.dtypes.float32)\n",
    "test_labels = tf.constant(test_labels, dtype=tf.dtypes.int32)\n",
    "net.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae33f7c48cc3e1271596d1bf08ce4d5e6d6f7129ff8bbb83bbb95ed8addff62"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
